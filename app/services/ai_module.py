"""AI moderation and assistant logic backed by OpenRouter.

Fixes applied in this file:
- Task 2:  detect_profanity() now uses profanity.txt via utils/profanity.py
- Task 2:  normalize_for_profanity() extended with full transliteration table
- Task 4:  assistant_reply() handles greetings and off-topic before topic check
- Task 3:  _is_bot_name_called() regex fixed (was double-escaped \\w)
- Task 9:  datetime.now(timezone.utc) replaces deprecated datetime.utcnow()
"""
from __future__ import annotations

import itertools
import json
import logging
import re
from datetime import datetime, timezone
from typing import Any

import aiohttp

from app.config import settings
from app.utils.profanity import load_profanity, load_profanity_exceptions
from app.utils.text import contains_profanity, split_profanity_words

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Module-level profanity dictionaries (loaded once at import time)
# ---------------------------------------------------------------------------
_PROFANITY_ROOTS: list[str] = load_profanity()
_PROFANITY_EXCEPTIONS: list[str] = load_profanity_exceptions()

# ---------------------------------------------------------------------------
# Transliteration table for normalize_for_profanity()
# ---------------------------------------------------------------------------
_TRANSLIT_TABLE: list[tuple[str, str]] = [
    # Full-word mappings first (longest possible matches)
    ("blyad", "Ð±Ð»ÑÐ´"),
    ("bljad", "Ð±Ð»ÑÐ´"),
    ("bliad", "Ð±Ð»ÑÐ´"),
    # Multi-char sequences (longer matches before single chars)
    ("bly", "Ð±Ð»Ñ"),
    ("blja", "Ð±Ð»Ñ"),
    ("blia", "Ð±Ð»Ñ"),
    ("pizd", "Ð¿Ð¸Ð·Ð´"),
    ("pisd", "Ð¿Ð¸Ð·Ð´"),
    ("pisÐ´", "Ð¿Ð¸Ð·Ð´"),
    ("xuy", "Ñ…ÑƒÐ¹"),
    ("xuj", "Ñ…ÑƒÐ¹"),
    ("khuy", "Ñ…ÑƒÐ¹"),
    ("khuj", "Ñ…ÑƒÐ¹"),
    ("huy", "Ñ…ÑƒÐ¹"),
    ("huj", "Ñ…ÑƒÐ¹"),
    ("suk", "ÑÑƒÐº"),
    ("cyk", "ÑÑƒÐº"),
    ("mud", "Ð¼ÑƒÐ´"),
    ("myd", "Ð¼ÑƒÐ´"),
    ("eby", "ÐµÐ±Ñ‹"),
    ("eban", "ÐµÐ±Ð°Ð½"),
    ("yoban", "Ñ‘Ð±Ð°Ð½"),
    ("yob", "Ñ‘Ð±"),
    ("jeb", "ÐµÐ±"),
    # Latin â†’ Cyrillic single chars (applied after multi-char)
    ("ph", "Ñ„"),
    ("a", "Ð°"),
    ("b", "Ð±"),
    ("c", "Ñ"),
    ("d", "Ð´"),
    ("e", "Ðµ"),
    ("f", "Ñ„"),
    ("g", "Ð³"),
    ("h", "Ñ…"),
    ("i", "Ð¸"),
    ("j", "Ð¹"),
    ("k", "Ðº"),
    ("l", "Ð»"),
    ("m", "Ð¼"),
    ("n", "Ð½"),
    ("o", "Ð¾"),
    ("p", "Ð¿"),
    ("q", "Ðº"),
    ("r", "Ñ€"),
    ("s", "Ñ"),
    ("t", "Ñ‚"),
    ("u", "Ñƒ"),
    ("v", "Ð²"),
    ("w", "Ð²"),
    ("x", "Ñ…"),
    ("y", "Ñƒ"),
    ("z", "Ð·"),
    # Digits / special chars used as letter substitutes
    ("0", "Ð¾"),
    ("1", "Ð¸"),
    ("3", "Ð·"),
    ("4", "Ñ‡"),
    ("5", "Ð±"),
    ("6", "Ð±"),
    ("!", "Ð¸"),
    ("@", "Ð°"),
    ("$", "Ñ"),
    # Ñ‘â†’Ðµ normalisation in dictionary lookups
    ("Ñ‘", "Ðµ"),
]


def normalize_for_profanity(text: str) -> str:
    """Normalize *text* for profanity detection.

    Applies:
    1. Lowercase conversion
    2. Multi-char transliteration (Latin sequences â†’ Cyrillic)
    3. Single-char Latin â†’ Cyrillic mapping
    4. Digit/special-char â†’ letter mapping
    5. Removal of non-alphabetic characters (after conversion)

    Fix (Task 2): previously only 6 basic Latinâ†’Cyrillic substitutions were
    made. Now a full transliteration table handles common leet/translit tricks.
    """
    result = text.lower()
    # Apply multi-char rules first (they are listed first in _TRANSLIT_TABLE)
    for src, dst in _TRANSLIT_TABLE:
        result = result.replace(src, dst)
    # Remove remaining non-Cyrillic/non-letter characters
    result = re.sub(r"[^Ð°-ÑÑ‘]", "", result)
    return result


# ---------------------------------------------------------------------------
# Profanity detection
# ---------------------------------------------------------------------------

# Fallback hard-coded roots (kept for safety in case profanity.txt is missing)
_FALLBACK_ROOTS = ["Ñ…ÑƒÐ¹", "Ñ…ÑƒÐµ", "Ð¿Ð¸Ð·Ð´", "ÐµÐ±Ð»", "ÑÑƒÐºÐ°", "Ð±Ð»ÑÐ´ÑŒ", "Ð¼ÑƒÐ´Ð°Ðº"]


def detect_profanity(text: str) -> bool:
    """Return True if *text* contains profanity.

    Fix (Task 2): now uses profanity.txt (loaded into _PROFANITY_ROOTS) in
    addition to the fallback hard-coded list, and applies full transliteration.
    """
    roots = _PROFANITY_ROOTS if _PROFANITY_ROOTS else _FALLBACK_ROOTS
    exceptions = _PROFANITY_EXCEPTIONS

    # Check both original and normalized forms
    for variant in (text, normalize_for_profanity(text)):
        words = split_profanity_words(variant)
        if contains_profanity(words, roots, exceptions):
            return True
    return False


# ---------------------------------------------------------------------------
# Reload hook (called by /reload_profanity command)
# ---------------------------------------------------------------------------

def reload_profanity_dicts() -> int:
    """Reload profanity.txt and exceptions from disk; return count of roots."""
    global _PROFANITY_ROOTS, _PROFANITY_EXCEPTIONS
    _PROFANITY_ROOTS = load_profanity()
    _PROFANITY_EXCEPTIONS = load_profanity_exceptions()
    logger.info("Profanity dicts reloaded: %d roots, %d exceptions",
                len(_PROFANITY_ROOTS), len(_PROFANITY_EXCEPTIONS))
    return len(_PROFANITY_ROOTS)


# ---------------------------------------------------------------------------
# Allowed / forbidden topic lists for assistant
# ---------------------------------------------------------------------------

_ALLOWED_ASSISTANT_TOPICS = (
    "Ð¶Ðº",
    "Ð¶Ð¸Ð»Ð¾Ð¹",
    "ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ",
    "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼",
    "Ð²ÑŠÐµÐ·Ð´",
    "Ð²Ñ‹ÐµÐ·Ð´",
    "Ð¿Ð°Ñ€ÐºÐ¾Ð²Ðº",
    "ÑÐ¾ÑÐµÐ´",
    "ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‰",
    "ÑƒÐº ",
    "Ñ‚ÑÐ¶",
    "Ð¿Ñ€Ð°Ð²Ð¸Ð»",
    "Ñ„Ð¾Ñ€ÑƒÐ¼",
    "Ñ‚Ð¾Ð¿Ð¸Ðº",
    "Ð¿Ð¾Ð´ÑŠÐµÐ·Ð´",
    "Ð»Ð¸Ñ„Ñ‚",
    "Ð¼ÑƒÑÐ¾Ñ€",
    "ÑƒÐ±Ð¾Ñ€Ðº",
    "ÐºÐ¾Ð½ÑÑŒÐµÑ€Ð¶",
    "Ð¾Ñ…Ñ€Ð°Ð½",
    "Ð´Ð¾Ð¼Ð¾Ñ„Ð¾Ð½",
    "ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€",
    "Ñ‡Ð°Ñ‚",
    "ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²",
    "Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€",
    "Ð±Ð°Ð½Ð½ÐµÑ€",
    "Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½",
    "ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¸Ðº",
    "Ð°Ñ€ÐµÐ½Ð´Ð°Ñ‚Ð¾Ñ€",
)

_FORBIDDEN_ASSISTANT_TOPICS = (
    "ÑÑƒÐ´",
    "Ð°Ð´Ð²Ð¾ÐºÐ°Ñ‚",
    "ÑŽÑ€Ð¸ÑÑ‚",
    "Ð¿Ñ€Ð¾ÐºÑƒÑ€Ð¾Ñ€",
    "Ð¿Ð¾Ð»Ð¸Ñ†Ð¸Ñ",
    "ÑƒÐ³Ð¾Ð»Ð¾Ð²Ð½",
    "ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½",
    "Ð¿Ñ€Ð¸ÑÑ‚Ð°Ð²Ñ‹",
    "Ð±Ð°Ð½ÐºÑ€Ð¾Ñ‚",
    "Ð½Ð°Ð»Ð¾Ð³",
    "Ð·Ð°Ð²ÐµÑ‰Ð°Ð½Ð¸",
    "Ð½Ð°ÑÐ»ÐµÐ´ÑÑ‚Ð²",
    "Ð¸Ð¿Ð¾Ñ‚ÐµÐº",
)

GREETING_WORDS = (
    "Ð¿Ñ€Ð¸Ð²ÐµÑ‚",
    "Ñ…Ð°Ð¹",
    "Ð·Ð´Ð°Ñ€Ð¾Ð²Ð°",
    "Ð·Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹",
    "Ð·Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ",
    "Ð´Ð¾Ð±Ñ€Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ",
    "Ð´Ð¾Ð±Ñ€Ð¾Ðµ ÑƒÑ‚Ñ€Ð¾",
    "Ð´Ð¾Ð±Ñ€Ñ‹Ð¹ Ð²ÐµÑ‡ÐµÑ€",
    "ÐºÑƒ",
    "Ñ…ÐµÐ»Ð»Ð¾",
    "Ñ…ÐµÐ»Ð»Ð¾Ñƒ",
    "Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽ",
    "ÑÐ°Ð»ÑŽÑ‚",
    "Ð±Ð¾Ð½Ð¶ÑƒÑ€",
    "Ñ…Ð¾Ð»Ð°",
)

# Carousel of fun replies when the bot is greeted
_MENTION_REPLIES = itertools.cycle([
    "ÐŸÑ€Ð¸Ð²ÐµÑ‚, ÑÐ¾ÑÐµÐ´! ðŸ‘‹ Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ð¿Ð¾ Ð–Ðš?",
    "Ðž, Ð¼ÐµÐ½Ñ ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÐ»Ð¸! Ð¯ Ð²ÐµÑÑŒ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ðŸ¤–",
    "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹! Ð¡Ð¿Ñ€Ð¾ÑÐ¸ Ð¿Ñ€Ð¾ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼ Ð¸Ð»Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° â€” Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ. ðŸ˜„",
    "ÐŸÑ€Ð¸Ð²ÐµÑ‚-Ð¿Ñ€Ð¸Ð²ÐµÑ‚! Ð§Ñ‚Ð¾ ÑÐ»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ Ð² Ð½Ð°ÑˆÐµÐ¼ Ð–Ðš?",
    "Ð—Ð´Ð°Ñ€Ð¾Ð²Ð°! Ð“Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ Ð»ÑŽÐ±Ñ‹Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼ Ð¾ Ð¶Ð¸Ð»Ð¾Ð¼ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐµ ðŸ ",
])


def _next_mention_reply() -> str:
    return next(_MENTION_REPLIES)


def is_greeting(text: str) -> bool:
    """Return True if *text* contains a greeting word."""
    lowered = text.lower()
    return any(w in lowered for w in GREETING_WORDS)


def is_assistant_topic_allowed(text: str) -> bool:
    """Return True if text is relevant to the residential complex."""
    lowered = text.lower()
    return any(kw in lowered for kw in _ALLOWED_ASSISTANT_TOPICS)


def is_forbidden_topic(text: str) -> bool:
    """Return True if text touches explicitly forbidden topics."""
    lowered = text.lower()
    return any(kw in lowered for kw in _FORBIDDEN_ASSISTANT_TOPICS)


# ---------------------------------------------------------------------------
# Bot-name mention filter helpers
# ---------------------------------------------------------------------------

def _is_bot_name_called(text: str, bot_names: list[str]) -> bool:
    """Return True if any of *bot_names* is mentioned in *text*.

    Fix (Task 3): the original code used rf'(?<!\\\\w)...' which in Python
    produced a literal backslash-w instead of a word-boundary assertion.
    The fix uses a proper raw string with (?<![\\w]) boundaries.
    """
    text_lower = text.lower()
    for name in bot_names:
        # Correct word-boundary pattern using raw string
        boundary_pattern = r"(?<![" + r"\w" + r"])" + re.escape(name.casefold()) + r"(?![" + r"\w" + r"])"
        if re.search(boundary_pattern, text_lower):
            return True
    return False


# ---------------------------------------------------------------------------
# Moderation prompt
# ---------------------------------------------------------------------------

_MODERATION_SYSTEM_PROMPT = """\
Ð¢Ñ‹ â€” AI-Ð¼Ð¾Ð´ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ñ‡Ð°Ñ‚Ð° Ð¶Ð¸Ð»Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ° (Ð–Ðš). Ð£Ñ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¸ â€” ÑÐ¾ÑÐµÐ´Ð¸, Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.

Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°: Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ JSON-Ð¾Ð±ÑŠÐµÐºÑ‚ ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»ÑÐ¼Ð¸:
- violation_type: ÑÑ‚Ñ€Ð¾ÐºÐ° ("profanity" | "aggression" | "spam" | "forbidden_link" | "offtopic" | "none")
- severity: Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 0 Ð´Ð¾ 3 (0 â€” Ð½ÐµÑ‚ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ, 1 â€” Ð»Ñ‘Ð³ÐºÐ¾Ðµ, 2 â€” ÑÑ€ÐµÐ´Ð½ÐµÐµ, 3 â€” Ñ‚ÑÐ¶Ñ‘Ð»Ð¾Ðµ)
- confidence: Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 0.0 Ð´Ð¾ 1.0
- action: ÑÑ‚Ñ€Ð¾ÐºÐ° ("none" | "warn" | "delete" | "mute_1h" | "mute_24h" | "ban")

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ severity:
- 0: Ð½ÐµÑ‚ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ, Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¶Ð°Ð»Ð¾Ð±Ð° Ð±ÐµÐ· Ð°Ð³Ñ€ÐµÑÑÐ¸Ð¸
- 1: Ð»Ñ‘Ð³ÐºÐ¾Ðµ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ðµ â€” Ð³Ñ€ÑƒÐ±Ð¾ÑÑ‚ÑŒ Ð±ÐµÐ· Ð¼Ð°Ñ‚Ð°, Ð¾Ñ„Ñ‚Ð¾Ð¿
- 2: ÑÑ€ÐµÐ´Ð½ÐµÐµ â€” Ð¼Ð°Ñ‚ Ð±ÐµÐ· Ð°Ð³Ñ€ÐµÑÑÐ¸Ð¸, ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ðµ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ
- 3: Ñ‚ÑÐ¶Ñ‘Ð»Ð¾Ðµ â€” ÑƒÐ³Ñ€Ð¾Ð·Ñ‹, Ð¼Ð°Ñ‚ Ñ Ð°Ð³Ñ€ÐµÑÑÐ¸ÐµÐ¹, ÑÐ¿Ð°Ð¼, Ð´Ð¾ÐºÑÐ¸Ð½Ð³

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹:
- severity 0 â†’ action: "none"
- severity 1 â†’ action: "warn"
- severity 2 â†’ action: "delete" (Ð¸Ð»Ð¸ "warn" ÐµÑÐ»Ð¸ ÑÐ¾Ð¼Ð½ÐµÐ²Ð°ÐµÑˆÑŒÑÑ)
- severity 3 â†’ action: "mute_24h" (Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ñ€Ð°Ð·), "ban" (Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾)

ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð·Ð°Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¼Ð°Ñ‚Ð° (ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸ÐµÐ¼ severity 3):
- "x*Ð¹", "Ñ…*Ð¹", "xÑƒÐ¹", "Ñ…ÑƒÐ¹", "Ñ…ÑƒÐ¹", "blyad", "Ð¿Ð¸3Ð´Ð°", "Ð¿*Ð·Ð´Ð°" â†’ Ð¼Ð°Ñ‚
- "bl***", "Ð¿***Ñ†", "Ðµ*Ð°Ñ‚ÑŒ" â†’ Ð¼Ð°Ñ‚

Ð¡Ð»Ð¾Ð²Ð°-Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ (ÐÐ• Ð¼Ð°Ñ‚):
- "Ñ…Ð»ÐµÐ±", "Ñ‚ÐµÐ±Ñ", "Ð½ÐµÐ±Ð¾", "ÑÑƒÐºÐ½Ð¾", "Ð±Ð»ÑÑ…Ð°-Ð¼ÑƒÑ…Ð°", "Ñ€Ñ‹Ð±Ð°Ðº", "Ð³Ñ€Ð¸Ð±Ñ‹"

ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð–Ðš: Ð¶Ð°Ð»Ð¾Ð±Ñ‹ Ð½Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹, Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ñ€Ð¾ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼, Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°, ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‰ÑƒÑŽ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑŽ â€” ÑÑ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ (severity 0 Ð¸Ð»Ð¸ 1 Ð±ÐµÐ· Ð°Ð³Ñ€ÐµÑÑÐ¸Ð¸).

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°.
"""

# ---------------------------------------------------------------------------
# Assistant system prompt
# ---------------------------------------------------------------------------

_ASSISTANT_SYSTEM_PROMPT = """\
Ð¢Ñ‹ â€” AI-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð¶Ð¸Ð»Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ° Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ AlexBot. Ð¢Ñ‹ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¸ Ð²ÐµÑÑ‘Ð»Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¶Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ð–Ðš.

Ð¢Ð²Ð¾Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸:
- ÐžÑ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ñ… Ð–Ðš, ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼Ðµ, Ð¿Ð°Ñ€ÐºÐ¾Ð²ÐºÐµ, ÑÐ¾ÑÐµÐ´ÑÑ…, ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‰ÐµÐ¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸
- Ð”Ð°Ð²Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ (2-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)
- ÐÐ° Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð²ÐµÑÐµÐ»Ð¾, 1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, Ð±ÐµÐ· ÐºÐ°Ð½Ñ†ÐµÐ»ÑÑ€Ð¸Ñ‚Ð°
- Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ðµ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ Ð–Ðš â€” Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð²ÐµÑÐµÐ»Ð¾, Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°Ñ‚ÑŒ ÑÐ¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ Ð–Ðš

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
- ÐÐ• Ð´Ð°Ð²Ð°Ð¹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÐ¾Ð²ÐµÑ‚Ð¾Ð² Ð¿Ð¾ ÑÑƒÐ´Ð°Ð¼, Ð°Ð´Ð²Ð¾ÐºÐ°Ñ‚Ð°Ð¼, Ð·Ð°ÐºÐ¾Ð½Ð¾Ð´Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ñƒ Ð²Ð½Ðµ Ð–Ðš
- ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð–Ðš â€” ÑÑ‚Ð¾ ÐÐ• ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ð½Ð¸Ñ… ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ð¾
- Ð–Ð°Ð»Ð¾Ð±Ñ‹ Ð½Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ Ð–Ðš â€” Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹, ÑÑ‚Ð¾ Ñ‚Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°
- Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ ÐºÐ°ÑÐ°ÐµÑ‚ÑÑ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð°Ð²Ð¸Ð» Ð–Ðš ÑÐ¾ÑÐµÐ´ÑÐ¼Ð¸ â€” Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ð¹ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ
- ÐÐ• Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð¹ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÑƒ, Ñ€ÐµÐ»Ð¸Ð³Ð¸ÑŽ, Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸

Ð¡Ñ‚Ð¸Ð»ÑŒ: Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹, Ð¸Ð½Ð¾Ð³Ð´Ð° Ñ Ð»Ñ‘Ð³ÐºÐ¸Ð¼ ÑŽÐ¼Ð¾Ñ€Ð¾Ð¼, Ð²ÑÐµÐ³Ð´Ð° Ð¿Ð¾ Ð´ÐµÐ»Ñƒ.
"""


# ---------------------------------------------------------------------------
# OpenRouter provider
# ---------------------------------------------------------------------------

class OpenRouterProvider:
    """Async client for the OpenRouter AI API."""

    def __init__(self) -> None:
        self._base_url = settings.openrouter_base_url.rstrip("/")
        self._api_key = settings.openrouter_api_key
        self._headers = {
            "Authorization": f"Bearer {self._api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/AlexBot",
            "X-Title": "AlexBot",
        }

    async def _chat_completion(
        self,
        messages: list[dict[str, str]],
        *,
        model: str | None = None,
        temperature: float = 0.7,
        max_tokens: int = 512,
        chat_id: int = 0,
    ) -> tuple[str, dict[str, Any]]:
        """Call OpenRouter chat completions and return (content, raw_response)."""
        payload = {
            "model": model or settings.ai_model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        url = f"{self._base_url}/chat/completions"
        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=self._headers, json=payload) as resp:
                resp.raise_for_status()
                data = await resp.json()

        content = data["choices"][0]["message"]["content"]
        return content, data

    async def moderate_message(
        self,
        text: str,
        *,
        chat_id: int = 0,
    ) -> dict[str, Any]:
        """Return a moderation verdict dict for *text*.

        Falls back to a local rule-based check if the API call fails.
        """
        try:
            content, _ = await self._chat_completion(
                [
                    {"role": "system", "content": _MODERATION_SYSTEM_PROMPT},
                    {"role": "user", "content": text},
                ],
                model=settings.ai_moderation_model,
                temperature=0.1,
                max_tokens=200,
                chat_id=chat_id,
            )
            return json.loads(content)
        except Exception as exc:
            logger.warning("OpenRouter moderation failed: %s; using local fallback", exc)
            return _local_moderation_fallback(text)

    async def assistant_reply(
        self,
        prompt: str,
        context: list[dict[str, str]] | None = None,
        *,
        chat_id: int = 0,
    ) -> str:
        """Generate an assistant reply for *prompt*.

        Fix (Task 4): greetings now return a fun reply without requiring a Ð–Ðš
        topic keyword. Off-topic messages get a friendly redirect rather than a
        hard refusal.

        If RAG is enabled (settings.ai_feature_rag), relevant knowledge-base
        fragments are injected into the system prompt before calling the LLM.
        """
        safe_prompt = prompt.strip()

        # 1. Check forbidden topics first
        if is_forbidden_topic(safe_prompt):
            return (
                "Ð­Ñ‚Ð¾ Ð·Ð° Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°Ð¼Ð¸ Ð¼Ð¾ÐµÐ¹ ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸. "
                "ÐŸÐ¾ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ. "
                "ÐÐ¾ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ð–Ðš â€” ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°Ð¹!"
            )

        # 2. Handle greetings â€” return carousel reply (no topic check needed)
        if is_greeting(safe_prompt):
            return _next_mention_reply()

        # 3. If off-topic â€” gentle redirect (applies even without API key)
        if not is_assistant_topic_allowed(safe_prompt):
            return (
                "Ð¥Ð¼, ÑÑ‚Ð¾ Ð½Ðµ ÑÐ¾Ð²ÑÐµÐ¼ Ð¿Ñ€Ð¾ Ð½Ð°Ñˆ Ð–Ðš, Ð½Ð¾ ÐµÑÐ»Ð¸ Ñ‡Ñ‚Ð¾ â€” "
                "ÑÐ¿Ñ€Ð¾ÑÐ¸ Ð¿Ñ€Ð¾ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼, Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð¸Ð»Ð¸ ÑÐ¾ÑÐµÐ´ÐµÐ¹ ðŸ˜„"
            )

        # 4. If AI is disabled, use local reply builder for Ð–Ðš topics
        if not self._api_key:
            return build_local_assistant_reply(safe_prompt)

        # 5. Build system prompt, optionally injecting RAG context
        system = _ASSISTANT_SYSTEM_PROMPT
        if settings.ai_feature_rag:
            try:
                from app.services.rag import search_rag, format_rag_context
                rag_results = search_rag(safe_prompt, top_k=3)
                rag_text = format_rag_context(rag_results)
                if rag_text:
                    system += f"\n\nÐ‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð–Ðš:\n{rag_text}"
            except Exception as exc:
                logger.warning("RAG search failed: %s", exc)

        # 6. Call LLM
        messages: list[dict[str, str]] = [{"role": "system", "content": system}]
        if context:
            messages.extend(context)
        messages.append({"role": "user", "content": safe_prompt})

        try:
            content, _ = await self._chat_completion(
                messages, chat_id=chat_id
            )
            return content
        except Exception as exc:
            logger.error("OpenRouter assistant call failed: %s", exc)
            return build_local_assistant_reply(safe_prompt)


def build_local_assistant_reply(prompt: str) -> str:
    """Simple rule-based fallback reply when AI is unavailable."""
    lowered = prompt.lower()
    if "ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼" in lowered:
        return "ÐŸÐ¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ ÑˆÐ»Ð°Ð³Ð±Ð°ÑƒÐ¼Ð° Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ Ñ„Ð¾Ñ€ÑƒÐ¼Ð° Ð¸Ð»Ð¸ Ð² Ð£Ðš."
    if "Ð¿Ñ€Ð°Ð²Ð¸Ð»" in lowered:
        return "ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð–Ðš Ð·Ð°ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ñ‹ Ð² Ñ‚Ð¾Ð¿Ð¸ÐºÐµ #Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°. Ð—Ð°Ð³Ð»ÑÐ½Ð¸ Ñ‚ÑƒÐ´Ð°!"
    if "ÑÐ¾ÑÐµÐ´" in lowered:
        return "Ð¡Ð¿Ð¾Ñ€Ñ‹ Ñ ÑÐ¾ÑÐµÐ´ÑÐ¼Ð¸ Ð»ÑƒÑ‡ÑˆÐµ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ñ‚ÑŒ Ð² Ñ‡Ð°Ñ‚Ðµ Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÑŒÑÑ Ð² Ð£Ðš."
    if "Ð¿Ð°Ñ€ÐºÐ¾Ð²Ðº" in lowered or "Ð²ÑŠÐµÐ·Ð´" in lowered:
        return "ÐŸÐ¾ Ð¿Ð°Ñ€ÐºÐ¾Ð²ÐºÐµ Ð¸ Ð²ÑŠÐµÐ·Ð´Ñƒ â€” ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸ Ñƒ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð° Ð¸Ð»Ð¸ Ð² Ð£Ðš."
    return "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ â€” Ð¿Ð¾ÑÑ‚Ð°Ñ€Ð°ÑŽÑÑŒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ! ðŸ˜Š"


def _local_moderation_fallback(text: str) -> dict[str, Any]:
    """Rule-based moderation used when the API is unavailable."""
    if detect_profanity(text):
        return {
            "violation_type": "profanity",
            "severity": 3,
            "confidence": 0.85,
            "action": "delete",
        }
    return {
        "violation_type": "none",
        "severity": 0,
        "confidence": 0.9,
        "action": "none",
    }
